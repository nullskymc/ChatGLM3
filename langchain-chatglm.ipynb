{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ea0d3f",
   "metadata": {},
   "source": [
    "## ChatGLM For RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffe459-036d-482f-8764-849ce9da7aa1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-24T11:59:43.679141Z",
     "iopub.status.busy": "2024-04-24T11:59:43.678768Z",
     "iopub.status.idle": "2024-04-24T11:59:47.480970Z",
     "shell.execute_reply": "2024-04-24T11:59:47.480310Z",
     "shell.execute_reply.started": "2024-04-24T11:59:43.679120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/nullskymc/ChatGLM3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip innstall modelscope\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"ZhipuAI/chatglm3-6b\", revision = \"v1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30803c-bbbc-4833-a2a0-281a2b807be1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ./ChatGLM3/requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0f464-b3f8-4247-8278-a2cef488c7f0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-24T12:21:20.544947Z",
     "iopub.status.busy": "2024-04-24T12:21:20.544624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./ChatGLM3/openai_api_demo/api_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c802180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.messages import AIMessage\n",
    "from langchain_community.llms.chatglm3 import ChatGLM3\n",
    "from langchain_community.embeddings import ModelScopeEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = \"http://127.0.0.1:8000/v1/chat/completions\" \n",
    "\n",
    "llm = ChatGLM3(\n",
    "    endpoint_url=endpoint_url,\n",
    "    max_tokens=80000,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "model_id = \"iic/nlp_corom_sentence-embedding_chinese-base\"\n",
    "embeddings = ModelScopeEmbeddings(model_id=model_id)\n",
    "\n",
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc773735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def pdf_loader(url):\n",
    "    # pdf文档加载器\n",
    "    loader = PyPDFLoader(url)\n",
    "    docs = loader.load_and_split()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "#以某一系列文本创建以faiss为后端的向量数据库，创建完后的数据库较大，耐心等待\n",
    "\n",
    "\n",
    "def create_vector_db(data_path, db_path, loader):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    data = loader(data_path)\n",
    "    docs = text_splitter.split_documents(data)\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    db.save_local(db_path)  #保存路径\n",
    "\n",
    "create_vector_db(\"./data_text.pdf\", \"./vector_db/water_db\", pdf_loader)  # 创建数据库样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29725a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 创建检索链\n",
    "\n",
    "input_text = '你的问题'\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        你的预设\n",
    "\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "\n",
    "        Question: {input}\n",
    "        \"\"\")\n",
    "\n",
    "new_db = FAISS.load_local(\"./vector_db/water_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "# 合成文档链\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retriever = new_db.as_retriever()  # 从向量数据库中检索\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": input_text})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
